{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcDc_-JKCvOW"
      },
      "source": [
        "#Fake News Classifier Using LSTM\n",
        "Dataset: https://www.kaggle.com/c/fake-news/data#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29-msXntC2Px"
      },
      "source": [
        "###Loading Data From Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "TSnf-j5k9Idj",
        "outputId": "2b43b97c-3ad5-438a-c2a2-feaf6a91919e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-11619ca9-5285-4a8a-aed7-3d7dcca678a2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-11619ca9-5285-4a8a-aed7-3d7dcca678a2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHVO9uTM-Ae3",
        "outputId": "62e61a81-4eea-43af-f7ce-3b14a1e9939f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 94% 35.0M/37.0M [00:00<00:00, 73.6MB/s]\n",
            "100% 37.0M/37.0M [00:00<00:00, 83.5MB/s]\n",
            "Downloading submit.csv to /content\n",
            "  0% 0.00/40.6k [00:00<?, ?B/s]\n",
            "100% 40.6k/40.6k [00:00<00:00, 42.0MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 96% 9.00M/9.42M [00:00<00:00, 91.4MB/s]\n",
            "100% 9.42M/9.42M [00:00<00:00, 86.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c fake-news"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4VJDAv1CsL7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72WLO7Vv-L33",
        "outputId": "3e0b975e-73ee-4ba7-8d92-4f12d980977d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n"
          ]
        }
      ],
      "source": [
        "!unzip train.csv.zip\n",
        "!unzip test.csv.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOnaqBjvC_Sc"
      },
      "source": [
        "###Importing Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "xWurTcpI-9Y1",
        "outputId": "77e2e320-0f59-43e3-ae4c-7b0ec052cb6a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>Darrell Lucus</td>\n",
              "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
              "      <td>Daniel J. Flynn</td>\n",
              "      <td>Ever get the feeling your life circles the rou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why the Truth Might Get You Fired</td>\n",
              "      <td>Consortiumnews.com</td>\n",
              "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
              "      <td>Jessica Purkiss</td>\n",
              "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
              "      <td>Howard Portnoy</td>\n",
              "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
              "      <td>Daniel Nussbaum</td>\n",
              "      <td>In these trying times, Jackie Mason is the Voi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Life: Life Of Luxury: Elton John’s 6 Favorite ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ever wonder how Britain’s most iconic pop pian...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
              "      <td>Alissa J. Rubin</td>\n",
              "      <td>PARIS  —   France chose an idealistic, traditi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Excerpts From a Draft Script for Donald Trump’...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Donald J. Trump is scheduled to make a highly ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>A Back-Channel Plan for Ukraine and Russia, Co...</td>\n",
              "      <td>Megan Twohey and Scott Shane</td>\n",
              "      <td>A week before Michael T. Flynn resigned as nat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              title  \\\n",
              "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
              "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
              "2   2                  Why the Truth Might Get You Fired   \n",
              "3   3  15 Civilians Killed In Single US Airstrike Hav...   \n",
              "4   4  Iranian woman jailed for fictional unpublished...   \n",
              "5   5  Jackie Mason: Hollywood Would Love Trump if He...   \n",
              "6   6  Life: Life Of Luxury: Elton John’s 6 Favorite ...   \n",
              "7   7  Benoît Hamon Wins French Socialist Party’s Pre...   \n",
              "8   8  Excerpts From a Draft Script for Donald Trump’...   \n",
              "9   9  A Back-Channel Plan for Ukraine and Russia, Co...   \n",
              "\n",
              "                         author  \\\n",
              "0                 Darrell Lucus   \n",
              "1               Daniel J. Flynn   \n",
              "2            Consortiumnews.com   \n",
              "3               Jessica Purkiss   \n",
              "4                Howard Portnoy   \n",
              "5               Daniel Nussbaum   \n",
              "6                           NaN   \n",
              "7               Alissa J. Rubin   \n",
              "8                           NaN   \n",
              "9  Megan Twohey and Scott Shane   \n",
              "\n",
              "                                                text  label  \n",
              "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
              "1  Ever get the feeling your life circles the rou...      0  \n",
              "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
              "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
              "4  Print \\nAn Iranian woman has been sentenced to...      1  \n",
              "5  In these trying times, Jackie Mason is the Voi...      0  \n",
              "6  Ever wonder how Britain’s most iconic pop pian...      1  \n",
              "7  PARIS  —   France chose an idealistic, traditi...      0  \n",
              "8  Donald J. Trump is scheduled to make a highly ...      0  \n",
              "9  A week before Michael T. Flynn resigned as nat...      0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv(\"fake-news/train.csv\")\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWEC2GM0DEcd"
      },
      "source": [
        "###Removing NaN Values from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kIPc0nVG_JgQ"
      },
      "outputs": [],
      "source": [
        "data=data.dropna()\n",
        "data.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofuQy_QWDVXj"
      },
      "source": [
        "###Extracting Dependent and Independent variables from data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QgSqaz58DOXt"
      },
      "outputs": [],
      "source": [
        "X = data.drop(\"label\",axis=1)\n",
        "y = data[\"label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FL0N3IRDmjS"
      },
      "source": [
        "###Checking The Shape of X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIbop-CiDit6",
        "outputId": "8b2c82f6-af2e-4882-d705-36df45d19950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(18285, 5)\n",
            "(18285,)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTDWpFElD3C2"
      },
      "source": [
        "###Importing the required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OM6GCzP1DvMz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 1. `import tensorflow as tf`\n",
        "\n",
        "- **TensorFlow**: It's an open-source machine learning library developed by Google. It's widely used for various kinds of ML tasks, including deep learning models like neural networks. In NLP, TensorFlow is often used for building and training models that work with text data.\n",
        "\n",
        "### 2. `from tensorflow.keras.layers import Embedding`\n",
        "\n",
        "- **Embedding Layer**: \n",
        "  - **Usage**: In NLP, this layer is used to convert numerical representations of words (like word indices) into dense vectors of fixed size. This is more efficient than one-hot encoded vectors as it captures more information (like semantic relationships) in fewer dimensions.\n",
        "  - **ML Project Context**: In text classification or sentiment analysis, an Embedding layer is often the first layer of the neural network, processing sequences of word indices and turning them into vectors that the model can learn from.\n",
        "\n",
        "### 3. `from tensorflow.keras.layers import LSTM`\n",
        "\n",
        "- **LSTM (Long Short-Term Memory) Layer**: \n",
        "  - **Usage**: LSTM is a type of Recurrent Neural Network (RNN) that is capable of learning long-term dependencies in sequence data. It's particularly useful for NLP tasks where the context or order of words is important, like in language modeling or text generation.\n",
        "  - **ML Project Context**: An LSTM layer can be used after an Embedding layer to process the word vectors and capture sequential dependencies between words in text data.\n",
        "\n",
        "### 4. `from tensorflow.keras.layers import Dense`\n",
        "\n",
        "- **Dense Layer**: \n",
        "  - **Usage**: A dense layer is a fully connected neural network layer where each input node is connected to each output node. It’s used for outputting predictions for the task at hand (like a classification or regression output).\n",
        "  - **ML Project Context**: In an NLP model, a Dense layer is often used after LSTM or other types of layers to interpret the features extracted from the text and make predictions.\n",
        "\n",
        "### 5. `from tensorflow.keras.preprocessing.text import one_hot`\n",
        "\n",
        "- **One-Hot Encoding for Text**:\n",
        "  - **Usage**: This function is used to convert text into a one-hot encoded numerical format. Each word is represented by a unique integer, and this integer is mapped to a binary vector of a fixed size (the vocabulary size) with all zeros except for the index of the word.\n",
        "  - **ML Project Context**: Before feeding text data into an Embedding layer, you often need to convert it into a numerical format. One-hot encoding is one way to do this, especially for smaller vocabulary sizes.\n",
        "\n",
        "### 6. `from tensorflow.keras.preprocessing.sequence import pad_sequences`\n",
        "\n",
        "- **Padding Sequences**:\n",
        "  - **Usage**: This function is used to ensure that all sequences in a list have the same length by padding them with zeros (or truncating them) to a specified length. This uniformity is required for batch processing in neural networks.\n",
        "  - **ML Project Context**: When working with text data, different texts might have different lengths. Padding is essential to create consistent input sizes for training neural network models.\n",
        "\n",
        "### 7. `from tensorflow.keras.models import Sequential`\n",
        "\n",
        "- **Sequential Model**:\n",
        "  - **Usage**: The Sequential model in Keras is a linear stack of layers. It's the simplest kind of Keras model for neural networks, where you can just add layers to the model in the order that they should be executed.\n",
        "  - **ML Project Context**: In NLP, a Sequential model might start with an Embedding layer, followed by LSTM layers or other types of layers, and end with a Dense layer for output. It's a straightforward way to build models layer by layer.\n",
        "\n",
        "In a typical NLP project, these components work together to process text data, extract features, and make predictions or analyze text. The specific architecture and choice of layers depend on the nature of the task (e.g., classification, sentiment analysis, language modeling) and the complexity of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5u8i_4cE7sz"
      },
      "source": [
        "###Preprocessing The Text \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYNnw9kAEiur",
        "outputId": "97aed590-c7c0-46e8-92a6-b1e109650e1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\E\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DgWyZdDaFaqw"
      },
      "outputs": [],
      "source": [
        "messages=X.copy()\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "for i in range(len(messages)):\n",
        "  review = re.sub(\"[^a-zA-Z]\",\" \",messages['title'][i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review = [ps.stem(word) for word in review if not word in stopwords.words('english')]  # (word not in stopwords) and stem(word)\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "text preprocessing in Natural Language Processing (NLP), using the Natural Language Toolkit (NLTK). Let's go through the code to understand and potentially optimize it.\n",
        "\n",
        "1. **Import Statements**: \n",
        "   - `import re` imports the regular expressions library, useful for text cleaning.\n",
        "   - `import nltk` and the subsequent download of stopwords are crucial for text processing.\n",
        "\n",
        "2. **Preprocessing Steps**:\n",
        "   - **Copying Data**: You're creating a copy of `X` into `messages`. It's good practice to avoid modifying the original dataset directly.\n",
        "   - **PorterStemmer Initialization**: `ps = PorterStemmer()` initializes the Porter Stemmer, a popular stemming algorithm.\n",
        "\n",
        "3. **Loop for Text Preprocessing**:\n",
        "   - You loop through each message and perform several steps:\n",
        "     - **Regular Expression Cleaning**: `re.sub(\"[^a-zA-Z]\",\" \",messages['title'][i])` removes everything except alphabetic characters. This is a common practice to remove numbers and special characters.\n",
        "     - **Lowercasing**: Converting the text to lower case to maintain uniformity.\n",
        "     - **Tokenization**: Splitting the text into individual words (`review.split()`).\n",
        "     - **Stopword Removal and Stemming**: Removing common English stopwords and applying stemming. This step reduces each word to its root form, removing inflections.\n",
        "\n",
        "4. **Creating the Corpus**:\n",
        "   - Finally, the processed review is joined back into a string and added to the `corpus` list.\n",
        "\n",
        "### Suggestions for Improvement:\n",
        "\n",
        "- **Efficiency in Stopword Removal**: You are checking stopwords inside the loop for each word. Consider creating a set of stopwords outside the loop. It will make lookup faster.\n",
        "  \n",
        "  ```python\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  ```\n",
        "\n",
        "- **Handling Empty Strings**: After preprocessing, some strings might become empty. It's good to add a condition to handle or filter them out.\n",
        "\n",
        "- **Parameterizing Function**: Consider encapsulating this logic into a function for reusability. This function can take parameters like the dataset and column names, making it more versatile.\n",
        "\n",
        "- **Error Handling**: Your code assumes that `X` has a column named 'title'. In practice, it’s good to add checks and error handling for cases where 'title' might not exist.\n",
        "\n",
        "- **Commenting**: Adding comments to your code can make it more readable and maintainable.\n",
        "\n",
        "Here's a revised version of your code with these suggestions:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\E\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "def preprocess_text(data, column_name):\n",
        "    ps = PorterStemmer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    corpus = []\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        if column_name in data.columns:\n",
        "            review = re.sub(\"[^a-zA-Z]\", \" \", data[column_name][i])\n",
        "            review = review.lower().split()\n",
        "            review = [ps.stem(word) for word in review if word not in stop_words]\n",
        "            review = ' '.join(review)\n",
        "            corpus.append(review if review else 'empty')  # Add 'empty' for empty reviews\n",
        "        else:\n",
        "            raise ValueError(f\"Column '{column_name}' not found in the dataset\")\n",
        "\n",
        "    return corpus\n",
        "\n",
        "corpus = preprocess_text(X, 'title')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSfvSUSQJVVy"
      },
      "source": [
        "### One Hot Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "converting preprocessed text into numerical form using one-hot encoding. This process is essential for preparing text data for various machine learning models. Let's discuss this step in detail.\n",
        "\n",
        "1. **One-Hot Encoding**: \n",
        "   - The function `one_hot` is typically used to represent words as integer indices. Each word in the corpus is assigned a unique integer value within the range of the vocabulary size. \n",
        "   - The `vocab_size`  chosen is 5000, which means setting a limit of 5000 unique words for model. Any words beyond this limit in corpus will not be considered.\n",
        "\n",
        "2. **Applying One-Hot Encoding**:\n",
        "   - using a list comprehension to apply the `one_hot` function to each preprocessed text (each 'review') in `corpus`. \n",
        "   - This results in `onehot_repr`, a list where each element is a list of integers, representing the one-hot encoded version of the corresponding text in the corpus.\n",
        "\n",
        "### Points to Consider:\n",
        "\n",
        "- **Vocabulary Size**: The choice of `vocab_size` is crucial. A smaller vocabulary might be insufficient for a large dataset, leading to a lot of words being ignored. Conversely, a very large vocabulary can increase computational complexity and memory usage.\n",
        "\n",
        "- **Out-of-Vocabulary Words**: In practice, it’s important to handle words that are not in the predefined vocabulary. This is typically done using a special token like `<UNK>` (unknown).\n",
        "\n",
        "- **Importing Necessary Functions**: Ensure that the `one_hot` function is imported or defined in your script. This function is often available in deep learning libraries like Keras.\n",
        "\n",
        "- **Further Steps**: After one-hot encoding,  consider converting these sequences into equal-length vectors using padding, especially if plan to use models like CNNs or RNNs for NLP task.\n",
        "\n",
        "Here's how to proceed, assuming using Keras:\n",
        "\n",
        "```python\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# One-Hot Encoding\n",
        "onehot_repr = [one_hot(words, vocab_size) for words in corpus]\n",
        "\n",
        "# Padding Sequences (Optional, based on your model requirement)\n",
        "max_sentence_length = 20  # Example length, choose according to your data\n",
        "padded_corpus = pad_sequences(onehot_repr, maxlen=max_sentence_length, padding='post')\n",
        "```\n",
        "\n",
        "This code first applies one-hot encoding and then pads each sequence to ensure that they all have the same length, which is a common requirement for neural network inputs.\n",
        "\n",
        "Remember, each step in preprocessing is crucial and has a significant impact on the performance of NLP model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyrwRvO0H56j",
        "outputId": "bf7de2ee-6f26-4b77-e20e-482a203207b9"
      },
      "outputs": [],
      "source": [
        "vocab_size=5000\n",
        "onehot_repr=[one_hot(words,vocab_size)for words in corpus] \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA1A54GjJpmC"
      },
      "source": [
        "###Applying Pad Sequences To Make Sentence Length Equal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKIESNPpJgmS",
        "outputId": "6b36b7e0-91d4-4db7-9bcd-d7543009bd16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ... 4718   47 4454]\n",
            " [   0    0    0 ...  342 2472  485]\n",
            " [   0    0    0 ... 4768 3973  363]\n",
            " ...\n",
            " [   0    0    0 ... 3498 2113 2272]\n",
            " [   0    0    0 ... 2703 2396  606]\n",
            " [   0    0    0 ... 4335 2402 4220]]\n"
          ]
        }
      ],
      "source": [
        "sent_length=20\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
        "print(embedded_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "progressing nicely into the deep learning part of NLP project. Here, building a neural network model using Keras, specifically for a text classification task. Let's break down the steps and the code:\n",
        "\n",
        "1. **Padding Sequences**: \n",
        "   - used `pad_sequences` to ensure all sequences in `embedded_docs` have the same length (`sent_length=20`). This is crucial for training neural networks, as they require inputs of uniform size.\n",
        "   - Padding with 'pre' means any sequences shorter than 20 tokens will be prepended with zeros.\n",
        "\n",
        "2. **Building the Neural Network**:\n",
        "   - **Embedding Layer**: The `Embedding` layer is set up with `vocab_size` as the input dimension and `embedding_vector_features=40`. This layer will learn an embedding for all words in the dataset.\n",
        "   - **LSTM Layer**: added an LSTM (Long Short-Term Memory) layer with 100 units. LSTM is effective for sequence data like text as it can capture long-term dependencies.\n",
        "   - **Dense Layer**: A Dense layer with a sigmoid activation function is used, indicating this model is for binary classification.\n",
        "\n",
        "3. **Compiling the Model**:\n",
        "   - used `binary_crossentropy` as the loss function and `adam` as the optimizer, which are standard choices for binary classification tasks.\n",
        "   - The metric chosen is 'accuracy'.\n",
        "\n",
        "4. **Model Summary**:\n",
        "   - `model.summary()` will print a summary representation of your model, showing each layer, its type, output shape, and number of parameters.\n",
        "\n",
        "### Things to Consider:\n",
        "\n",
        "- **Input Length Consistency**: Ensure that the input length specified in the `Embedding` layer (`input_length=sent_length`) matches the length of the sequences in `embedded_docs`.\n",
        "\n",
        "- **Model Architecture Tuning**: The architecture (number of LSTM units, number of embedding features, etc.) can greatly influence the model's performance. Consider experimenting with these parameters.\n",
        "\n",
        "- **Overfitting Check**: With deep learning models, especially LSTMs, there's a risk of overfitting. Monitor the training and validation accuracy, and consider using techniques like dropout or regularization if necessary.\n",
        "\n",
        "- **Training the Model**: After compiling the model, need to train it using the `model.fit()` method, supplying training data and labels, and specifying the number of epochs and batch size.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U48RiuSUKBCl"
      },
      "source": [
        "#Creating Model for Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb4enDPjJ1Ax",
        "outputId": "61838c7b-0053-45c6-c81f-9973cdde0a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 20, 40)            200000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               56400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,501\n",
            "Trainable params: 256,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "'''embedding_vector_features=40\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,embedding_vector_features,input_length=sent_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 20, 40)            200000    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               56400     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,501\n",
            "Trainable params: 256,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 20, 40)            200000    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               56400     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1)                 0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,503\n",
            "Trainable params: 256,503\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Here's a slight enhancement to include a Dropout layer for regularization:\n",
        "\n",
        "\n",
        "from keras.layers import Dropout\n",
        "\n",
        "embedding_vector_features=40\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,embedding_vector_features,input_length=sent_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "model.add(Dropout(0.3))  # Dropout layer for regularization\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model Summary\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "# The Dropout layer will help in preventing overfitting by randomly setting a fraction of input units to 0 at each update during training time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9iy6oOE6LBGI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X_final=np.array(embedded_docs)\n",
        "y_final=np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of X_final: 18285\n",
            "Length of y_final: 18285\n"
          ]
        }
      ],
      "source": [
        "print(\"Length of X_final:\", len(X_final))\n",
        "print(\"Length of y_final:\", len(y_final))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_final = y_final[:len(X_final)]  # Truncate y_final to match X_final's length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "P5ely4NRLKpS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odahTueqLOqO",
        "outputId": "facb4641-36d9-4cfb-ee26-f8c443199242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "192/192 [==============================] - 7s 8ms/step - loss: 0.6899 - accuracy: 0.5576 - val_loss: 0.6870 - val_accuracy: 0.5665\n",
            "Epoch 2/10\n",
            "192/192 [==============================] - 1s 6ms/step - loss: 0.6858 - accuracy: 0.5667 - val_loss: 0.6850 - val_accuracy: 0.5665\n",
            "Epoch 3/10\n",
            "192/192 [==============================] - 1s 6ms/step - loss: 0.6847 - accuracy: 0.5667 - val_loss: 0.6845 - val_accuracy: 0.5665\n",
            "Epoch 4/10\n",
            "192/192 [==============================] - 1s 6ms/step - loss: 0.6843 - accuracy: 0.5667 - val_loss: 0.6843 - val_accuracy: 0.5665\n",
            "Epoch 5/10\n",
            "192/192 [==============================] - 1s 6ms/step - loss: 0.6843 - accuracy: 0.5667 - val_loss: 0.6843 - val_accuracy: 0.5665\n",
            "Epoch 6/10\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.6486 - accuracy: 0.6833 - val_loss: 0.5887 - val_accuracy: 0.8949\n",
            "Epoch 7/10\n",
            "192/192 [==============================] - 1s 6ms/step - loss: 0.5710 - accuracy: 0.8065 - val_loss: 0.5371 - val_accuracy: 0.9042\n",
            "Epoch 8/10\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.5250 - accuracy: 0.8270 - val_loss: 0.5018 - val_accuracy: 0.9041\n",
            "Epoch 9/10\n",
            "192/192 [==============================] - 1s 7ms/step - loss: 0.4951 - accuracy: 0.8353 - val_loss: 0.4694 - val_accuracy: 0.9150\n",
            "Epoch 10/10\n",
            "192/192 [==============================] - 1s 6ms/step - loss: 0.4705 - accuracy: 0.8429 - val_loss: 0.4483 - val_accuracy: 0.9112\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1b9b6303dc0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IINnPadOLW5S"
      },
      "source": [
        "###Performance Metrics And Accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YdMgDt-LROB",
        "outputId": "8d8d76e1-b7e2-4e11-a835-248ada506efc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "189/189 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[3091,  328],\n",
              "       [ 208, 2408]], dtype=int64)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.round(y_pred).astype(int)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EknICONKLkSp",
        "outputId": "43077b61-359e-441f-9bfa-842482489d4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9111847555923778"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjAOBFXSLnQg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Fake_News_Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
